

The notion of interpolation has been introduced by Craig in \cite{Craig57linear}.
Loosely speaking, given two formulas $A$ and $B$ such that $A$ implies $B$, an interpolant $I$ is a formula which is implied by $A$ and which itself implies $B$, as visualised in Figure~\ref{fig:interpol}.
Hence it in some sense captures the logical content of $A$ which necessarily makes $B$ true and therefore acts as a link between these formulas.

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[
			implies/.style={double,double equal sign distance,-implies},
			mynode/.style={circle,outer sep=3pt}
		]
		\node[mynode] (A) at (0,0) {$A$};
		\node[mynode] (B) at (4,0) {$B$};
		\node[mynode] (I) at (2,-1.5) {$I$};

		%\draw[->,implies] (A) to (B);
		\draw (A) edge[implies]  (B);
		\draw (A) edge[implies]  (I);
		\draw (I) edge[implies]  (B);

	\end{tikzpicture}
	\label{fig:interpol}
	\caption{Given two formulas $A$ and $B$ such that $A$ implies $B$, an interpolant is a formula $I$ which is implied by $A$ and which implies $B$.}
\end{figure}
Moreover, interpolants are not arbitrary formulas, but their language is restricted to those symbols, which are common to both original formulas.
Thus they represent the logical connection solely by statements on notions, which are of significance to both $A$ and $B$.
This criterion establishes that the actually represented content meets some level of relevance and avoids unnecessary information, thereby ensuring that interpolants enjoy the favorable property of conciseness.

As Craig has shown that interpolants always exist in classical first-order logic, they can be regarded as a justification for material implication in this logic:
If an implication in classical logic holds under any circumstance, then there is a formula which contains the logical content explaining this implication.
Or conversely, if such a summary of a potential implication does not exist, then the implication itself does not and in fact can not hold in general.
Furthermore, if formulas are concerned with different matters (such that their language is disjoint), there certainly can not be a logical relation between them, as for such formulas, only trivial interpolants can be found.

Craig interpolation has been and is still studied with respect to a wide variety of logics.
Most notably, it holds for propositional and classical first-order logic.
These facts can be proven by different means:
Interpolants can be directly extracted from proofs of logical relations of formulas, thus showing their existence in a constructive manner.
Alternatively, also semantic proofs for the existence of interpolants can be given:
Assuming the non-existence of interpolants, one can build a model contradicting an assumed logical relation of the original formulas.

The applications of Craig interpolation are manifold:
As a theoretic tool, it can for instance be employed to prove Beth's definability theorem or to show lower bounds on the length of proofs of propositional proof systems (\cite{krajivcek1997interpolation,Pudlak97}).
In recent years, it has been discovered that interpolants serve well in the area of model checking as a means to find formulas overapproximating the set of reachable states of a program (\cite{McMillan03}), which is now an active area of research.
Furthermore, in the field of program analysis, there are approaches making use of interpolation to extract information about the changes of program state inflicted by loop iterations in order to detect loop invariants  (\cite{weissenbacher2010}).
This list is however merely a non-exhaustive selection of relevant use cases of interpolation.


In this thesis, we consider classical first-order logic with equality.
We present different proofs of the interpolation theorem with a focus on constructive proofs which give rise to concrete algorithms for finding interpolants.
The central calculus employed in this thesis is the resolution calculus including paramodulation.

In Chapter~\ref{chap:interpolation_and_proof_theory}, among defining the notation and calculi, we present the interpolation theorem as such including several strengthenings and its application in the proof of Beth's definability theorem.

A first proof is given in Chapter~\ref{chap:reduction}, where the added complexity of equality and function symbols is expressed in a logic without these concepts in order to prove the interpolation theorem in the reduced logic.

Chapter~\ref{chap:two_phases} then presents a constructive proof of the interpolation theorem by Huang in a somewhat modified form based on extracting interpolants from resolution refutations in two phases.

In Chapter~\ref{chap:one_phase}, we introduce an algorithm based on the one described in the previous chapter which combines the two phases and thereby is capable of producing different interpolants.

The proof-theoretic proofs of the previous chapters are then complemented by a model-theoretic one in Chapter~\ref{chap:semantic} based on Robinson's joint consistency theorem.

Finally, Appendix~\ref{chap:huang} presents the aforementioned proof by Huang in a version closer to his publication.



