\documentclass[,%fontsize=11pt,%
			paper=a4,% 
			%DIV12, % mehr text pro seite als defaultyyp
			DIV12,
			%DIV=calc,%
			%twoside=false,%
			liststotoc,
			bibtotoc,
			draft=false,% final|draft % draft ist platzsparender (kein code, bilder..)
			%titlepage,
			numbers=noendperiod
			]{scrartcl}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

\usepackage{enumerate}
\usepackage{paralist}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,backgrounds,graphs,%
matrix,patterns,arrows,decorations.pathmorphing,decorations.pathreplacing,%
positioning,fit,calc,decorations.text,shadows%
}


\input{../latex_header.tex}

%\usepackage{bussproof}

%\usepackage{vaucanson-g}
\usepackage{amssymb}
\usepackage{latexsym}

% for color-highlighted code
%\usepackage{color} % for grey comments
%\usepackage{alltt}

%\usepackage[doublespacing]{setspace}
\usepackage[onehalfspacing]{setspace}
%\usepackage[singlespacing]{setspace}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{comment}
\usepackage{color}
\usepackage[final]{listings} % sourcecode in document
\usepackage{url}      % for urls
\usepackage{multicol}
\usepackage{float}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage[authoryear]{natbib} % \cite ; square|round etc.
%\usepackage[numbers,square]{natbib}
%\usepackage[square, authoryear]{natbib}
%\usepackage[language=english]{biblatex}

%\bibliographystyle{plain}
\bibliographystyle{alpha}
%\bibliographystyle{alphadin}
%\bibliographystyle{dinat}
%\bibliographystyle{chicago}
%\bibliographystyle{plainnat}

\bibdata{bib.bib}

\renewcommand*{\partformat}{\partname\ \thepart\ -}
\let\partheadmidvskip\

		\newcommand{\comp}{\ensuremath{\text{comp}}}
% smaller url style
\makeatletter
\def\url@leostyle{%
\@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother
\urlstyle{leo}

\newcommand{\myfig}[5] {
 \begin{figure}[tbph]
	 \centering
	 \includegraphics[#3]{#1}
	 \caption[#4]{#5}
	 \label{fig:#2}
 \end{figure}
}

\subject{Master Thesis Proposal}
\title{Interpolation in First Order Logic with Equality}
\author{Bernhard Mallinger \medskip \\
Advisor: Ass.Prof.\ Stefan Hetzl}
%\date{13. November 2007}

%\usepackage{fancyhdr}
%\setlength{\headrulewidth}{0.0pt}
\pagestyle{plain}

\definecolor{grey}{gray}{.35} % for grey commnts
\lstset{language=Python,%
escapeinside={@}{@},
extendedchars=false,%
%inputencoding=utf8x,%
basicstyle=\ttfamily\small,%
commentstyle=\color{grey},%
%keywordstyle=,% no bold tt in standard font
%captionpos=b,
tabsize=2,
showstringspaces=false,
breaklines=true,
breakindent=0pt,
numbers=left
}

% just for screen-display!
%\usepackage{newcent}

%\newcommand{\ex}[2]{\section*{Exercise #1} \textbf{#2} }
%\newcommand{\ex}[2]{\subsection*{Exercise #1: #2} }

\newcommand{\myt}[1]{\ensuremath{\;\text{ #1 }\;}}
\newcommand{\myts}[1]{\ensuremath{\text{ #1 }}}

%\setlength{\parindent}{0em}
%\usepackage{thmtools} % actually already in latex_header.tex ...

\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}


\begin{document}

\maketitle

\section{Motivation and problem statement}
\label{motivation}

After decades of continued research, the area of software verification still lacks effective methods for reasoning about real world programs, which is necessary to prove vital safety or liveness properties.
The emergence of symbolic model checking and bounded model checking constitute considerable advances.
Here, the reachable states of a program are described by means of abstraction, i.e.\ automatically derived predicates overapproximate them. 
Furthermore, in dealing with loops with an a priori unknown number of iterations, it is necessary to infer loop invariants in order to enable giving a meaningful guarantee of the state of the program afterwards.

In recent years, the approach of applying Craig interpolation to solve both of these problems enjoyed increasing popularity, especially after successful applications for instance in \cite{McMillan03} for use in abstraction or \cite{weissenbacher2010} for use in loop invariant generation.

The Interpolation theorem is a long known basic result of mathematical logic.
Interpolants lay bare certain logical relations between formulas or sets of formulas in a concise way. 
This process is fully analytic in the sense that interpolants can efficiently be calculated from proofs.
Leveraging the tremendous progress of automatic deduction systems in the last decades, obtaining the required proofs is feasible.

For practical applicability, often relatively weak formalisms such as propositional logic or equational logic with uninterpreted function symbols are studied. 


%TODO no efficient algorithms for computing interpolants are known, even though a basic procedure is already provided in \cite{craig57linear}.

%However for first-order logic with equality, TODO no efficient algorithms for computing interpolants are known, even though a basic procedure is already provided in \cite{craig57linear}.


\begin{comment}
Software verification
Model checking
Derive invariants
interpolation by its nature disregards all but the predicates relevant to a certain property
can be used for predicate refinement in cegar

often restricted to weaker logics, application to more powerful formalisms such as fol with equality is relevant 
\end{comment}

\section{Aim of the work}

%TODO
%This thesis aims to work towards finding an algorithm to calculate interpolants in first-order logic in the presence of equality.
%Currently no procedures of practical applicability are known for this logic,  
%This should be accomplished by either improving existing solutions such as the aforementioned procedure by Craig or exploring a novel approach.

This thesis aims at giving comprehensive account of existing techniques and results with respect to interpolation in full first order logic with equality from an algorithmic perspective.
This includes different proofs of interpolation results with a focus on constructive proofs which give rise to concrete and implementation-ready procedures for finding interpolants.
These algorithms, as listed in \ref{algos}, will be presented, analysed and compared. 

Dependant on these findings, improvements or extensions of these algorithms will be investigated.
More concretely, developing an efficient interpolation algorithm for LK and extending existing approaches without equality to include equality are among the research interests.

Non-constructive methods, especially of a model theoretic nature, will be treated in order to form a theoretical baseline and to give a broader picture.
In this spirit, further corollaries and also applications of the interpolation theorem will be presented.



\section{Methodology and approach}

As the problem at hand is a well-defined mathematical task, standard mathematical methodology applies.

Determined by the results in the investigations, implementations of the algorithms are deemed scientifically valuable but most likely beyond the scope of this thesis.


\section{State of the art}

Current research and application is rooted in the fundamental result by Craig \cite{craig57linear}, here given in a formulation suitable for resolution calculus\footnote{Also known as \emph{reverse interpolation}}:

\begin{thm}[Interpolation]
	Let $A$ and $B$ be first-order sentences such that $A \land B$ is refutable. 
	Then there exists an interpolant $I$ such that
	\begin{compactenum}
		\item $ A \limpl I$ is valid 
		\item $I \land B$ is unsatisfiable
		\item the non-logical symbols of $I$ are only those that appear in both $A$ and $B$.
	\end{compactenum}
\end{thm}

This basic result has been proven in different formalisms using different syntactic methods (cf.~e.g.~\cite{craig57linear}; \cite{takeuti1987proof}; \cite{krajivcek1997interpolation}; \cite{Pudlak97}), but also via semantic, model theoretic means (cf.~e.g.~\cite{shoenfield1967mathematical}, section~5.2; \cite{chang1990model}, theorem~2.2.20).
To this end, the interpolation theorem can be seen as a corollary Robinson's joint consistency theorem, but even more, latter can also be proven from the former. 
This suggest a close relation between one the one hand the proof-theoretic and on the other hand the model-theoretic view.

Another major corollary of the interpolation theorem is given by Beth in form of the definability theorem, which shows that the notions of implicit and explicit definition coincide.
In shallow terms, an implicit definitions refers to a definition by usage in a formula, whereas an explicit definition gives a definition in terms of another formula.
The non-trivial direction of this theorem states that implicit definitions can be converted into explicit ones and it can be proved by using the interpolant as explicit definition.


\subsection{Interpolation algorithms}
\label{algos}

Constructive proofs of the interpolation theorem directly give rise to algorithms for computing interpolants.
For instance in \cite{takeuti1987proof}, the well known Maehara lemma is used in the proof, which forms an efficient procedure for extracting interpolants from first-order LK proofs but does not consider equality and function symbols.
It is unknown to the author whether the approach can be generalized to include

\cite{Huang95} describes an algorithm for first order logic with equality in the resolution calculus. In a two stage approach, an initially constructed relational interpolant is later stripped of non-common constant and function symbols by overbinding them.
\cite{Pudlak97} and \cite{krajivcek1997interpolation} independently propose similar approaches, whereas both are restricted to propositional logic.

In \cite{baaz2011methods}, also a two step approach is proposed for first order logic without equality.
The interesting difference to \cite{Huang95} lies in the proof method:
While in the latter the overbinding in the second stage only works for the kind of interpolants which have been constructed in the first stage of this very algorithm, the method of \cite{baaz2011methods} argues about correctness of the overbinding based directly on the properties of relational interpolants.
This more flexible and powerful approach appears to fail in the presence of equality.

Another noteworthy and in fact one of the first interpolation algorithms of empirical relevance was introduced in \cite{McMillan03}.




\section{Relevance to the curriculum of Computational Intelligence}

Logic as core machinery of computer science is featured prominently in the curriculum of Computational Intelligence in the mandatory module ``Logic and Computability'' as well as the module ``Logic, Mathematics, and Theoretical Computer Science'', but is also vital in the theoretic foundations of other areas. 

The logic used in this thesis, first-order logic with equality, clearly is among the most common and useful ones; the interpolation theorem is hereby a celebrated result.
As argued in section \ref{motivation}, advancements in this field have direct consequences for the area of formal verification, which is also featured in the curriculum.

The following courses possess a direct relation to the topic of this thesis: 
\begin{itemize}
	\item Formal Methods in Computer Science
	\item Proof Theory 1 
	\item Logic and Computability 
	\item Advanced Mathematical Logic 
\end{itemize}


\nocite{*} % display all entries of bib-file

\bibliography{bib}

\end{document}
